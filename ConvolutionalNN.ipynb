{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "This notebook demonstrates a convolutional neural network that predicts the whether an Ising Model lattice was simulated below or above the Curie Temperature.\n",
    "\n",
    "### The CNN we'll use is based on that in the paper\n",
    "- Convolution Layer: The first hidden layer, with 64 2by2 filters, a unit stride, no padding, periodic boundary conditions, and ReLU.\n",
    "- We'll flatten here\n",
    "- Fully Connected Layer: Fully connected layer wit h 64 Relu Unit.\n",
    "- Dropout to avoid overfitting\n",
    "- Output Layer: two outputs, softmax\n",
    "\n",
    "The paper also has Adam as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as r\n",
    "import MetroSim as met\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.layers as l\n",
    "import tensorflow.keras.utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training and test data\n",
    "# Must be normalized\n",
    "TJ = 2/np.log(1+np.sqrt(2)) # The known phase change temperature\n",
    "\n",
    "def pol(x): # Function to immitate a Heaveside step\n",
    "    if x>TJ:\n",
    "        x = 1\n",
    "    else: \n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "data = pd.read_csv('16_25000_2800.csv') # Download a premade data set\n",
    "# randomizing the data with the temperature index\n",
    "randomized = np.random.permutation(data)\n",
    "r= [i[1:] for i in randomized] \n",
    "name = [pol(i[0]) for i in randomized]\n",
    "\n",
    "\n",
    "train_images = np.array([i.reshape(16,16,1) for i in r[:60000]])\n",
    "train_labels = np.array([i for i in name[:60000]])\n",
    "test_images = np.array([i.reshape(16,16,1) for i in r[60001:]])\n",
    "test_labels = np.array([i for i in name[60001:]])\n",
    "\n",
    "train_labels = u.to_categorical(train_labels)\n",
    "test_labels = u.to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 16, 16, 1)\n",
      "(60000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_images))\n",
    "print(np.shape(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        320       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                921664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 922,114\n",
      "Trainable params: 922,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the Model\n",
    "model = Sequential() # Defining the model as Sequential\n",
    "model.add(l.Conv2D(64,(2,2), activation='relu', input_shape=(16, 16,1)))\n",
    "model.add(l.Flatten())\n",
    "model.add(l.Dense(64, activation='relu'))\n",
    "model.add(l.Dropout(0.5))\n",
    "model.add(l.Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and Fitting\n",
    "\n",
    "- Loss: 'binary_crossentropy' is the standard for binary outputs.\n",
    "- Optimizer: The paper uses adam for the optimizer, but using sgd gets me slightly better results. \n",
    "- Metrics\n",
    "- Batch Size: The larger the batch size, the quicker it will run. But that may degrade the accuracy and the computer might not be able to handle all that data at once.\n",
    "- Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/6\n",
      "Epoch 2/6\n",
      "Epoch 3/6\n",
      "Epoch 4/6\n",
      "Epoch 5/6\n",
      "Epoch 6/6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x679a0c470>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels,\n",
    "          batch_size=100,\n",
    "          epochs=5,\n",
    "          verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9577066\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=3)\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
